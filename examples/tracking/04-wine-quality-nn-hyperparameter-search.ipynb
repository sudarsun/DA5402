{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e61adc72",
   "metadata": {},
   "source": [
    "## Compare runs, choose a model, and deploy it to a REST API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154dd928",
   "metadata": {},
   "source": [
    "### Ref https://mlflow.org/docs/latest/getting-started/quickstart-2/index.html\n",
    "\n",
    "![alt](https://mlflow.org/docs/latest/assets/images/quickstart_tracking_overview-2fc1efa4bce294fc4114ce35fa34fe04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f1cc1f",
   "metadata": {},
   "source": [
    "* Run a hyperparameter sweep on a training script\n",
    "* Compare the results of the runs in the MLflow UI\n",
    "* Choose the best run and register it as a model\n",
    "* Deploy the model to a REST API\n",
    "* Build a container image suitable for deployment to a cloud platform\n",
    "\n",
    "As an ML Engineer or MLOps professional, you can use MLflow to compare, share, and deploy the best models produced by the team. In this quickstart, you will use the MLflow Tracking UI to compare the results of a hyperparameter sweep, choose the best run, and register it as a model. Then, you will deploy the model to a REST API. Finally, you will create a Docker container image suitable for deployment to a cloud platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5009b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:29:23.012431Z",
     "start_time": "2024-11-19T17:29:22.893587Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-20T11:10:09.778618Z",
     "iopub.status.busy": "2024-11-20T11:10:09.778406Z",
     "iopub.status.idle": "2024-11-20T11:10:09.903366Z",
     "shell.execute_reply": "2024-11-20T11:10:09.902505Z",
     "shell.execute_reply.started": "2024-11-20T11:10:09.778598Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setup the tracker URI\n",
    "!export MLFLOW_TRACKING_URI=http://localhost:5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd40b85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:29:24.181658Z",
     "start_time": "2024-11-19T17:29:23.229202Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-20T11:10:25.345901Z",
     "iopub.status.busy": "2024-11-20T11:10:25.345624Z",
     "iopub.status.idle": "2024-11-20T11:10:27.095973Z",
     "shell.execute_reply": "2024-11-20T11:10:27.095660Z",
     "shell.execute_reply.started": "2024-11-20T11:10:25.345874Z"
    }
   },
   "outputs": [],
   "source": [
    "# install the required packages\n",
    "!pip -q install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee3a039",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:29:26.357347Z",
     "start_time": "2024-11-19T17:29:24.183738Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-20T11:10:47.457653Z",
     "iopub.status.busy": "2024-11-20T11:10:47.457289Z",
     "iopub.status.idle": "2024-11-20T11:10:49.301764Z",
     "shell.execute_reply": "2024-11-20T11:10:49.301456Z",
     "shell.execute_reply.started": "2024-11-20T11:10:47.457612Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3114cb8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-26T10:03:53.589594Z",
     "start_time": "2024-02-26T10:03:53.584502Z"
    }
   },
   "source": [
    "#### Now load the dataset and split it into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e6efeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:30:59.892424Z",
     "start_time": "2024-11-19T17:30:59.869734Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-20T11:10:59.316898Z",
     "iopub.status.busy": "2024-11-20T11:10:59.316296Z",
     "iopub.status.idle": "2024-11-20T11:10:59.351782Z",
     "shell.execute_reply": "2024-11-20T11:10:59.350998Z",
     "shell.execute_reply.started": "2024-11-20T11:10:59.316858Z"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"wine-quality-hyperopt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce55e77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:31:01.804126Z",
     "start_time": "2024-11-19T17:31:01.801504Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-20T11:11:47.358823Z",
     "iopub.status.busy": "2024-11-20T11:11:47.358522Z",
     "iopub.status.idle": "2024-11-20T11:11:47.361635Z",
     "shell.execute_reply": "2024-11-20T11:11:47.361083Z",
     "shell.execute_reply.started": "2024-11-20T11:11:47.358798Z"
    }
   },
   "outputs": [],
   "source": [
    "last_run = mlflow.last_active_run()\n",
    "last_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065e50f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:31:02.504243Z",
     "start_time": "2024-11-19T17:31:02.500707Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-20T11:11:48.969194Z",
     "iopub.status.busy": "2024-11-20T11:11:48.968957Z",
     "iopub.status.idle": "2024-11-20T11:11:48.973326Z",
     "shell.execute_reply": "2024-11-20T11:11:48.972506Z",
     "shell.execute_reply.started": "2024-11-20T11:11:48.969173Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve the run, including dataset information\n",
    "if last_run != None:\n",
    "    run = mlflow.get_run(mlflow.last_active_run().info.run_id)\n",
    "    dataset_info = run.inputs.dataset_inputs[0].dataset\n",
    "    print(f\"Dataset name: {dataset_info.name}\")\n",
    "    print(f\"Dataset digest: {dataset_info.digest}\")\n",
    "    print(f\"Dataset profile: {dataset_info.profile}\")\n",
    "    print(f\"Dataset schema: {dataset_info.schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9cffcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:31:04.632217Z",
     "start_time": "2024-11-19T17:31:04.160823Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-20T11:12:31.547644Z",
     "iopub.status.busy": "2024-11-20T11:12:31.547413Z",
     "iopub.status.idle": "2024-11-20T11:12:31.732090Z",
     "shell.execute_reply": "2024-11-20T11:12:31.731477Z",
     "shell.execute_reply.started": "2024-11-20T11:12:31.547623Z"
    }
   },
   "outputs": [],
   "source": [
    "if last_run == None:\n",
    "    print(\"Reading from URI.\")\n",
    "    source_uri = \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv\"\n",
    "    # Load dataset\n",
    "    data = pd.read_csv(source_uri, sep=\";\",)\n",
    "    mlflow_ds = mlflow.data.from_pandas(data, source=source_uri)\n",
    "else:\n",
    "    print(\"Reading the dataset used by the previous run.\")\n",
    "    # Load the dataset's source, which downloads the content from the source URL to the local filesystem\n",
    "    dataset_source = mlflow.data.get_source(dataset_info)\n",
    "    data = pd.read_csv(dataset_source.load(), sep=\";\")\n",
    "    mlflow_ds = mlflow.data.from_pandas(data, source = dataset_source.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560b5445",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:31:05.380138Z",
     "start_time": "2024-11-19T17:31:05.364697Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-20T11:12:36.237280Z",
     "iopub.status.busy": "2024-11-20T11:12:36.237045Z",
     "iopub.status.idle": "2024-11-20T11:12:36.257413Z",
     "shell.execute_reply": "2024-11-20T11:12:36.256577Z",
     "shell.execute_reply.started": "2024-11-20T11:12:36.237258Z"
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002d0535",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:31:06.678682Z",
     "start_time": "2024-11-19T17:31:06.669837Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-20T11:12:48.876140Z",
     "iopub.status.busy": "2024-11-20T11:12:48.875898Z",
     "iopub.status.idle": "2024-11-20T11:12:48.885918Z",
     "shell.execute_reply": "2024-11-20T11:12:48.885322Z",
     "shell.execute_reply.started": "2024-11-20T11:12:48.876120Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train, test = train_test_split(data, test_size=0.25, random_state=42)\n",
    "train_x = train.drop([\"quality\"], axis=1).values\n",
    "train_y = train[[\"quality\"]].values.ravel()\n",
    "test_x = test.drop([\"quality\"], axis=1).values\n",
    "test_y = test[[\"quality\"]].values.ravel()\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(\n",
    "    train_x, train_y, test_size=0.2, random_state=42\n",
    ")\n",
    "signature = infer_signature(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1f108b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:31:08.026173Z",
     "start_time": "2024-11-19T17:31:08.022129Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-20T11:12:50.603446Z",
     "iopub.status.busy": "2024-11-20T11:12:50.603222Z",
     "iopub.status.idle": "2024-11-20T11:12:50.607912Z",
     "shell.execute_reply": "2024-11-20T11:12:50.607329Z",
     "shell.execute_reply.started": "2024-11-20T11:12:50.603425Z"
    }
   },
   "outputs": [],
   "source": [
    "train_x.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55622bd8",
   "metadata": {},
   "source": [
    "### Then letâ€™s define the model architecture and train the model. The train_model function uses MLflow to track the parameters, results, and model itself of each trial as a child run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fb7fed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:31:11.619465Z",
     "start_time": "2024-11-19T17:31:11.613060Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-20T11:39:31.571593Z",
     "iopub.status.busy": "2024-11-20T11:39:31.571234Z",
     "iopub.status.idle": "2024-11-20T11:39:31.576889Z",
     "shell.execute_reply": "2024-11-20T11:39:31.576174Z",
     "shell.execute_reply.started": "2024-11-20T11:39:31.571562Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(params, epochs, train_x, train_y, valid_x, valid_y, test_x, test_y):\n",
    "    # Define model architecture\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.Input([train_x.shape[1]]),\n",
    "            #keras.layers.Normalization(mean=np.mean(train_x), variance=np.var(train_x)),\n",
    "            keras.layers.Dense(params[\"nodes\"], activation=params[\"act_fn\"]),\n",
    "            keras.layers.Dense(1),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.SGD(\n",
    "            learning_rate=params[\"lr\"], momentum=params[\"momentum\"]\n",
    "        ),\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=[keras.metrics.RootMeanSquaredError()],\n",
    "    )\n",
    "    \n",
    "    #print(model.summary())\n",
    "\n",
    "    # Train model with MLflow tracking\n",
    "    with mlflow.start_run(nested=True):\n",
    "        model.fit(\n",
    "            train_x,\n",
    "            train_y,\n",
    "            validation_data=(valid_x, valid_y),\n",
    "            epochs=epochs,\n",
    "            batch_size=64,\n",
    "        )\n",
    "        # Evaluate the model\n",
    "        eval_result = model.evaluate(valid_x, valid_y, batch_size=64)\n",
    "        eval_rmse = eval_result[1]\n",
    "\n",
    "        # Log parameters and results\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"eval_rmse\", eval_rmse)\n",
    "\n",
    "        # Log model\n",
    "        mlflow.tensorflow.log_model(model, \"model\", signature=signature)\n",
    "\n",
    "        return {\"loss\": eval_rmse, \"status\": STATUS_OK, \"model\": model}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9f8f67",
   "metadata": {},
   "source": [
    "### The `objective` function takes in the hyperparameters and returns the results of the train_model function for that set of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c398a816",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:31:16.704871Z",
     "start_time": "2024-11-19T17:31:16.701513Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-20T11:39:32.813360Z",
     "iopub.status.busy": "2024-11-20T11:39:32.813134Z",
     "iopub.status.idle": "2024-11-20T11:39:32.816626Z",
     "shell.execute_reply": "2024-11-20T11:39:32.816090Z",
     "shell.execute_reply.started": "2024-11-20T11:39:32.813339Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # MLflow will track the parameters and results for each run\n",
    "    result = train_model(\n",
    "        params,\n",
    "        epochs=3,\n",
    "        train_x=train_x,\n",
    "        train_y=train_y,\n",
    "        valid_x=valid_x,\n",
    "        valid_y=valid_y,\n",
    "        test_x=test_x,\n",
    "        test_y=test_y,\n",
    "    )\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb50c27",
   "metadata": {},
   "source": [
    "Let's define the search space for `Hyperopt`. In this case, we want to try different values of `learning-rate` and `momentum`. Hyperopt begins its optimization process by selecting an initial set of hyperparameters, typically chosen at random or based on a specified domain space. This domain space defines the range and distribution of possible values for each hyperparameter. After evaluating the initial set, Hyperopt uses the results to update its probabilistic model, guiding the selection of subsequent hyperparameter sets in a more informed manner, aiming to converge towards the optimal solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53cb406",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:31:17.768295Z",
     "start_time": "2024-11-19T17:31:17.765249Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-20T11:39:33.779038Z",
     "iopub.status.busy": "2024-11-20T11:39:33.778794Z",
     "iopub.status.idle": "2024-11-20T11:39:33.783178Z",
     "shell.execute_reply": "2024-11-20T11:39:33.782415Z",
     "shell.execute_reply.started": "2024-11-20T11:39:33.779016Z"
    }
   },
   "outputs": [],
   "source": [
    "nodes = [64, 128, 32]\n",
    "act_fns = [\"relu\", \"sigmoid\", \"tanh\"]\n",
    "\n",
    "space = {\n",
    "    \"lr\": hp.loguniform(\"lr\", np.log(1e-6), np.log(1e-1)),\n",
    "    \"momentum\": hp.uniform(\"momentum\", 0.0, 1.0),\n",
    "    \"nodes\": hp.choice(\"nodes\", nodes),\n",
    "    \"act_fn\": hp.choice(\"act_fn\", act_fns),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f83116",
   "metadata": {},
   "source": [
    "Finally, we will run the hyperparameter sweep using Hyperopt, passing in the objective function and search space. Hyperopt will try different hyperparameter combinations and return the results of the best one. We will store the best parameters, model, and evaluation metrics in MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff31878c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T17:31:49.880134Z",
     "start_time": "2024-11-19T17:31:18.909405Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-20T11:39:34.699565Z",
     "iopub.status.busy": "2024-11-20T11:39:34.699334Z",
     "iopub.status.idle": "2024-11-20T11:41:20.626490Z",
     "shell.execute_reply": "2024-11-20T11:41:20.626128Z",
     "shell.execute_reply.started": "2024-11-20T11:39:34.699543Z"
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"wine-quality-run-hyperopt\"):\n",
    "    # log the input artifact\n",
    "    mlflow.log_input(mlflow_ds, \"training\")\n",
    "        \n",
    "    # Conduct the hyperparameter search using Hyperopt\n",
    "    trials = Trials()\n",
    "    best = fmin(\n",
    "        fn=objective,\n",
    "        space=space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=10,\n",
    "        trials=trials,\n",
    "    )\n",
    "\n",
    "    # Fetch the details of the best run\n",
    "    best_run = sorted(trials.results, key=lambda x: x[\"loss\"])[0]\n",
    "\n",
    "    # Log the best parameters, loss, and model\n",
    "    mlflow.log_params(best)\n",
    "    mlflow.log_metric(\"eval_rmse\", best_run[\"loss\"])\n",
    "    mlflow.tensorflow.log_model(best_run[\"model\"], \"model\", signature=signature)\n",
    "\n",
    "    # Print out the best parameters and corresponding loss\n",
    "    best['nodes'] = nodes[best['nodes']]\n",
    "    best['act_fn'] = act_fns[best['act_fn']]\n",
    "    \n",
    "    print(f\"Best parameters: {best}\")\n",
    "    print(f\"Best eval rmse: {best_run['loss']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb7df86",
   "metadata": {},
   "source": [
    "### Serve the model locally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbc6cc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-26T11:10:54.861348Z",
     "start_time": "2024-02-26T11:10:54.854718Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install pyenv from https://github.com/pyenv/pyenv#installation\n",
    "# install libffi-dev liblzma-dev libbz2-dev libssl-dev before spawning the model serving.\n",
    "# if you come across _ctypes not found error,\n",
    "# sudo apt-get install libffi-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe88f42",
   "metadata": {},
   "source": [
    "#### MLflow allows you to easily serve models produced by any run or model version. You can serve the model you just registered by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e26fde0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-26T11:44:59.783345Z",
     "start_time": "2024-02-26T11:44:59.777961Z"
    }
   },
   "outputs": [],
   "source": [
    "!mlflow models serve -m \"models:/wine-quality-hyperopt/2\" --port 5002 --host 0.0.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6ce879",
   "metadata": {},
   "source": [
    "#### To test the model, you can send a request to the REST API using the curl command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57d6d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -d '{\"dataframe_split\": {\"columns\": [\"fixed acidity\",\"volatile acidity\",\"citric acid\",\"residual sugar\",\"chlorides\",\"free sulfur dioxide\",\"total sulfur dioxide\",\"density\",\"pH\",\"sulphates\",\"alcohol\"], \"data\": [[7,0.27,0.36,20.7,0.045,45,170,1.001,3,0.45,8.8]]}}' -H 'Content-Type: application/json' -X POST localhost:5002/invocations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751ed24f",
   "metadata": {},
   "source": [
    "### Build a container image for your model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe98652",
   "metadata": {},
   "source": [
    "Most routes toward deployment will use a container to package your model, its dependencies, and relevant portions of the runtime environment. You can use MLflow to build a Docker image for your model.\n",
    "\n",
    "#### Note: Install [nvidia-container-toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html) to use GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d52c664",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-26T12:59:26.046350Z",
     "start_time": "2024-02-26T12:59:26.040900Z"
    }
   },
   "outputs": [],
   "source": [
    "!mlflow models build-docker --model-uri \"models:/wine-quality/1\" --name \"qs_mlops\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cc4117",
   "metadata": {},
   "source": [
    "This command builds a Docker image named qs_mlops that contains your model and its dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ff5c66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-26T12:59:49.908110Z",
     "start_time": "2024-02-26T12:59:49.901537Z"
    }
   },
   "outputs": [],
   "source": [
    "!docker run -p 5002:8080 qs_mlops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca266d39",
   "metadata": {},
   "source": [
    "This Docker run command runs the image you just built and maps port 5002 on your local machine to port 8080 in the container. You can now send requests to the model using the same curl command as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae615fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-26T13:00:12.844241Z",
     "start_time": "2024-02-26T13:00:12.838712Z"
    }
   },
   "outputs": [],
   "source": [
    "!curl -d '{\"dataframe_split\": {\"columns\": [\"fixed acidity\",\"volatile acidity\",\"citric acid\",\"residual sugar\",\"chlorides\",\"free sulfur dioxide\",\"total sulfur dioxide\",\"density\",\"pH\",\"sulphates\",\"alcohol\"], \"data\": [[7,0.27,0.36,20.7,0.045,45,170,1.001,3,0.45,8.8]]}}' -H 'Content-Type: application/json' -X POST localhost:5002/invocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ad876b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
